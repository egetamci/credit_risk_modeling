# -*- coding: utf-8 -*-
"""main_code_file.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IPXTJ9O_mJ_dNMgZBw2JydL_HTK2qvCe
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import statsmodels.api as sm

# Read the CSV file from the Resources folder into a Pandas DataFrame
df = pd.read_csv("/content/loan_approval_dataset.csv")

# Display the first few rows of the DataFrame
df.head()

# Check for missing values in the DataFrame
df.isnull().sum()

# Display the data types of each column
df.dtypes

# Display the column names
df.keys()

# Preprocess the 'loan_status' column for binary classification
df[' loan_status'].replace(' Approved', 1, inplace=True)
df[' loan_status'].replace(' Rejected', 0, inplace=True)

# Visualize data distribution using boxplots
fig, axes = plt.subplots(3, 2, figsize=(10, 10))
sns.boxplot(data=df, x=' income_annum', ax=axes[0, 0])
sns.boxplot(data=df, x=' loan_amount', ax=axes[0, 1])
sns.boxplot(data=df, x=' loan_term', ax=axes[1, 0])
sns.boxplot(data=df, x=' cibil_score', ax=axes[1, 1])
sns.boxplot(data=df, x=' residential_assets_value', ax=axes[2, 0])
sns.boxplot(data=df, x=' commercial_assets_value', ax=axes[2, 1])

# Create a pie chart to visualize loan status distribution
loan_status_counts = df[' loan_status'].value_counts()
plt.figure(figsize=(8, 8))
plt.pie(loan_status_counts.values, autopct='%1.1f%%', startangle=140)

# Preprocess categorical features for logistic regression
df[' education'].replace(' Graduate', 1, inplace=True)
df[' education'].replace(' Not Graduate', 0, inplace=True)
df[' self_employed'].replace(' Yes', 1, inplace=True)
df[' self_employed'].replace(' No', 0, inplace=True)

# Define a function to categorize IV values
def iv_critique(iv_value, feature):
    if iv_value < 0.02:
        return f"The '{feature}' parameter is deemed unnecessary for predicting the Loan Status."
    elif iv_value < 0.1:
        return f"The '{feature}' parameter exhibits weak predictive capability for Loan Status."
    elif iv_value < 0.3:
        return f"The '{feature}' parameter demonstrates moderate predictive power for Loan Status."
    else:
        return f"The '{feature}' parameter displays strong predictive power for Loan Status."

# Define a function to calculate WOE and IV
def calculate_woe_iv(data, feature, target):
    bins = pd.qcut(data[feature], q=10, duplicates='drop')
    woe_iv = pd.DataFrame(index=bins.cat.categories)
    woe_iv.index.name = 'Bin'
    woe_iv['Total'] = data.groupby(bins)[target].count()
    woe_iv['Event'] = data.groupby(bins)[target].sum()
    woe_iv['Non_Event'] = woe_iv['Total'] - woe_iv['Event']
    woe_iv['% Event'] = woe_iv['Event'] / woe_iv['Event'].sum()
    woe_iv['% Non-Event'] = woe_iv['Non_Event'] / woe_iv['Non_Event'].sum()
    woe_iv['WOE'] = np.log(woe_iv['% Event'] / woe_iv['% Non-Event'])
    woe_iv['IV'] = (woe_iv['% Event'] - woe_iv['% Non-Event']) * woe_iv['WOE']
    return woe_iv

# Perform WOE and IV calculation for each feature
Effected_parameters = df.drop(columns=['loan_id', ' loan_status'])
for feature in Effected_parameters.columns:
    woe_iv_feature = calculate_woe_iv(df, feature, ' loan_status')
    print("WOE and IV (" + feature + "):")
    print(woe_iv_feature.iloc[:, 5:7])  # Print WOE and IV columns
    print("Total IV Value for " + feature + " Parameter:", woe_iv_feature["IV"].sum())
    print(iv_critique(woe_iv_feature["IV"].sum(), feature))
    print("\n")

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(Effected_parameters, df[' loan_status'], test_size=0.9, random_state=200)

# Train a logistic regression model
logReg = LogisticRegression().fit(x_train, y_train)
# Make predictions
y_pred = logReg.predict(x_test)
# Calculate prediction accuracy
Pred_success = accuracy_score(y_test, y_pred)
print(Pred_success)

# Create a logistic regression model using statsmodels
model = sm.Logit(y_train, x_train)
result = model.fit()  # Fit the model to the training data
print(result.summary())  # Display model summary

# Measuring of the model's ability to distinguish between classes in binary classification tasks
from sklearn.metrics import roc_auc_score
auc_score = roc_auc_score(y_test, y_pred)
print("AUC Score:", auc_score)